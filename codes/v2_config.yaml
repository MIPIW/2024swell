originalData:
  dataset_CT: ["wikitext", "wikitext-103-v1"] # used in anywhere
  dataset_FT: "conll2003" # used in anywhere
  raw_CT: "/home/hyohyeongjang/2024SWELL/data_raw/ct_raw.pk" # used in anywhere
  raw_FT: "/home/hyohyeongjang/2024SWELL/data_raw/ft_raw.pk" # used in anywhere

dataStats: 
  bag_of_word_CT: "/home/hyohyeongjang/2024SWELL/meta/BOW_CT.pk" # used in getWords
  bag_of_word_FT: "/home/hyohyeongjang/2024SWELL/meta/BOW_FT.pk" # used in getWords
  cnt_pos_CT: "/home/hyohyeongjang/2024SWELL/meta/cnt_pos_CT.pk" # used in getWords
  cnt_pos_FT: "/home/hyohyeongjang/2024SWELL/meta/cnt_pos_FT.pk" # used in getWords
  file_wordStats_CT: "/home/hyohyeongjang/2024SWELL/meta/word_ct.pk" # used in getWords
  file_wordStats_FT: "/home/hyohyeongjang/2024SWELL/meta/word_ft.pk" # used in getWords

pplScores:
  scores_original_CT: "/home/hyohyeongjang/2024SWELL/scores/score_CT_original_{}.pk" # used in getScores
  scores_masked_CT: "/home/hyohyeongjang/2024SWELL/scores/score_CT_mask_{}.pk" # used in getScores
  checkpoint_pplModel: "meta-llama/Meta-Llama-3-8B-Instruct" # used in getScores
  num_cores: 40 # making dataset

contFiles:
  ratio: [0.25, 0.5, 0.75, 1.0]
  data_CT: "/home/hyohyeongjang/2024SWELL/data_CT/CT_{}_{}_{}.pk" # used in getFiles
  data_FT: "/home/hyohyeongjang/2024SWELL/data_FT/FT_{}_{}_{}.pk" # used in getFiles

contTrain:
  checkpoint_baseModel: "FacebookAI/roberta-base" # used in continualTrain
  checkpoint_CTModel: "/home/hyohyeongjang/2024SWELL/weights/CT/CT_{}_{}_{}" # used in continualTrain
  max_seq_len: 512
  batch_size: 64 # 64에 약 25000MiB(100%)
  do_RandomInitialize: False
  num_cores_train: 10

fineTune:
  checkpoint_FTModel: "/home/hyohyeongjang/2024SWELL/weights/FT/FT_{}_{}_{}_{}" # used in continualTrain
